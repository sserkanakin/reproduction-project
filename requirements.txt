# Base requirements for the MMIU LLaVA Evaluation Pipeline

# For PyTorch, choose the version appropriate for your target environment (CPU or GPU)
# Example for CPU-only (smaller, but LLaVA inference will be very slow):
# torch torchvision torchaudio
# Example for CUDA 11.8 (check https://pytorch.org/get-started/previous-versions/ for others):
# torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
# Example for CUDA 12.1:
torch --index-url https://download.pytorch.org/whl/cu121
torchvision --index-url https://download.pytorch.org/whl/cu121
torchaudio --index-url https://download.pytorch.org/whl/cu121

# For Hugging Face Transformers and LLaVA models
transformers>=4.38.0 # Ensure a recent version for LLaVA compatibility
accelerate>=0.26.0   # ADD THIS LINE - Required for bitsandbytes quantization

# Image processing
Pillow>=9.0.0

# OpenAI API for choice conversion
openai>=1.0.0

# For loading .env files
python-dotenv>=1.0.0

# For progress bars
tqdm>=4.60.0

# Optional: For 8-bit quantization with --use_quantization
# bitsandbytes is primarily for Linux with NVIDIA GPUs.
bitsandbytes>=0.41.0